{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpkYHwCqk7W-"
      },
      "source": [
        "![MuJoCo banner](https://raw.githubusercontent.com/google-deepmind/mujoco/main/banner.png)\n",
        "\n",
        "# <h1><center>Tutorial  <a href=\"https://colab.research.google.com/github/google-deepmind/mujoco_warp/blob/main/notebooks/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"140\" align=\"center\"/></a></center></h1>\n",
        "\n",
        "This notebook provides an introductory tutorial for [**MuJoCo Warp (MJWarp)**](https://github.com/google-deepmind/mujoco_warp/), an implementation of MuJoCo written with [NVIDIA Warp](https://github.com/NVIDIA/warp).\n",
        "\n",
        "**A Colab runtime with GPU acceleration is required.** If you're using a CPU-only runtime, you can switch using the menu \"Runtime > Change runtime type\".\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvyGCsgSCxHQ"
      },
      "source": [
        "# All imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbZxYDxzoz5R"
      },
      "outputs": [],
      "source": [
        "!uv pip install \"git+https://github.com/google-deepmind/mujoco_warp.git\"\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!uv pip install mediapy\n",
        "\n",
        "# Set up GPU rendering.\n",
        "from google.colab import files\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "import mediapy as media\n",
        "import warp as wp\n",
        "import numpy as np\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# avoid warp output in cells\n",
        "wp.config.quiet = True\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  import mujoco_warp as mjw\n",
        "  mjw.put_model(mujoco.MjModel.from_xml_string('<mujoco/>'))\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj4-Xmx4DFaq"
      },
      "source": [
        "# Introduction to MuJoCo Warp\n",
        "\n",
        "MuJoCo Warp (MJWarp) is an implementation of MuJoCo using [NVIDIA Warp](https://github.com/NVIDIA/warp).  MJWarp is optimized for running large batches of simulation in parallel on NVIDIA GPUs.  You can use MJWarp to rapidly train or evaluate robot models with faithful transfer between the simulated robot and the real robot.\n",
        "\n",
        "In this notebook, we will demonstrate the basic usage of MJWarp. Let's get started with a simpler example! The entrypoint into MJWarp is through MuJoCo, so first we load a MuJoCo model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNus3mbbDz6a"
      },
      "outputs": [],
      "source": [
        "xml = \"\"\"\n",
        "<mujoco>\n",
        "  <worldbody>\n",
        "    <light name=\"top\" pos=\"0 0 1\"/>\n",
        "    <body name=\"box_and_sphere\" euler=\"0 0 -30\">\n",
        "      <joint name=\"swing\" type=\"hinge\" axis=\"1 -1 0\" pos=\"-.2 -.2 -.2\"/>\n",
        "      <geom name=\"red_box\" type=\"box\" size=\".2 .2 .2\" rgba=\"1 0 0 1\"/>\n",
        "      <geom name=\"green_sphere\" pos=\".2 .2 .2\" size=\".1\" rgba=\"0 1 0 1\"/>\n",
        "    </body>\n",
        "  </worldbody>\n",
        "</mujoco>\n",
        "\"\"\"\n",
        "\n",
        "mj_model = mujoco.MjModel.from_xml_string(xml)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZShF9-o_JLm3"
      },
      "source": [
        "Let's run the simulation in MuJoCo and render the trajectory. This example is taken from the [MuJoCo tutorial](https://colab.sandbox.google.com/github/google-deepmind/mujoco/blob/main/python/tutorial.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDlPlX05I3m-"
      },
      "outputs": [],
      "source": [
        "mj_data = mujoco.MjData(mj_model)\n",
        "renderer = mujoco.Renderer(mj_model)\n",
        "\n",
        "# enable joint visualization option:\n",
        "scene_option = mujoco.MjvOption()\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_JOINT] = True\n",
        "\n",
        "duration = 3.8  # (seconds)\n",
        "framerate = 60  # (Hz)\n",
        "\n",
        "frames = []\n",
        "mujoco.mj_resetData(mj_model, mj_data)\n",
        "while mj_data.time < duration:\n",
        "  mujoco.mj_step(mj_model, mj_data)\n",
        "  if len(frames) < mj_data.time * framerate:\n",
        "    renderer.update_scene(mj_data, scene_option=scene_option)\n",
        "    pixels = renderer.render()\n",
        "    frames.append(pixels)\n",
        "\n",
        "# Simulate and display video.\n",
        "media.show_video(frames, fps=framerate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po5oykJbFQbj"
      },
      "source": [
        "Next we take the MuJoCo `MjModel` and `MjData`, and place them on the GPU using MJWarp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSpoOWqeEC3P"
      },
      "outputs": [],
      "source": [
        "model = mjw.put_model(mj_model)\n",
        "data = mjw.put_data(mj_model, mj_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rxMMSs4OJJf"
      },
      "source": [
        "Below, we print the `qpos` from MuJoCo and MJWarp. Notice that the `qpos` for the `mjData` is a numpy array living on the CPU, while the `qpos` for `Data` is a Warp array living on the GPU device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOD582pfOLP-"
      },
      "outputs": [],
      "source": [
        "print(mj_data.qpos, type(mj_data.qpos))\n",
        "print(data.qpos, type(data.qpos), data.qpos.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m70b_RxBJOyd"
      },
      "source": [
        "Now let's run the same exact simulation on the GPU device using MJWarp!\n",
        "\n",
        "In the example below, we use `mjw.step` instead of `mujoco.mj_step`. For each frame, we convert the `mjw.Data` back to `mjData` so that we can use the MuJoCo renderer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr29xq0-JRQv"
      },
      "outputs": [],
      "source": [
        "mjw.reset_data(model, data)\n",
        "frames = []\n",
        "while data.time.numpy() < duration:\n",
        "  mjw.step(model, data)\n",
        "  if len(frames) < data.time.numpy() * framerate:\n",
        "    mjw.get_data_into(mj_data, mj_model, data)\n",
        "    renderer.update_scene(mj_data, scene_option=scene_option)\n",
        "    frames.append(renderer.render())\n",
        "\n",
        "media.show_video(frames, fps=framerate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXsQ4qO2KO3Q"
      },
      "source": [
        "We will improve the performance of the simulation in two ways:\n",
        "\n",
        "1) Create many copies of the simulation state and step them in parallel\n",
        "2) Record the sequence of CUDA operations in `mjw.step`, so that they can be [executed on GPU as a single graph](https://nvidia.github.io/warp/modules/concurrency.html#synchronization-and-graph-capture).\n",
        "\n",
        "In the example below, we create 4096 copies of `Data` on GPU, and we execute a single graph on device using Warp's `ScopedCapture` feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrdrcKRVK6w9"
      },
      "outputs": [],
      "source": [
        "data = mjw.put_data(mj_model, mj_data, nworld=4096)\n",
        "\n",
        "with wp.ScopedCapture() as capture:\n",
        "  mjw.step(model, data)\n",
        "\n",
        "wp.capture_launch(capture.graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MJWarp not only operates on batches of `Data` - it also operate on batches of `Model` fields.\n",
        "\n",
        "When MJWarp finds a batched `Model` field, it distributes field values evenly across the `Data` copies.  For example, the following steps 4096 copies of `Data`, and half of them have upside down gravity."
      ],
      "metadata": {
        "id": "1jWB-gX_Xrps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = mjw.put_data(mj_model, mj_data, nworld=4096)\n",
        "model.opt.gravity = wp.array([[0, 0, -9.81], [0, 0, 9.81]], dtype=wp.vec3f)\n",
        "mjw.step(model, data)"
      ],
      "metadata": {
        "id": "14Ex5oHpbjcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MuJoCo Warp for robot learning\n",
        "\n",
        "Although you can use MJWarp directly, it is also integrated into some existing toolkits for training robots using machine learning:\n",
        "\n",
        "* [MuJoCo Playground](https://github.com/google-deepmind/mujoco_playground) is\n",
        "a comprehensive suite of GPU-accelerated environments for robot learning research and sim-to-real.  It is written in JAX but integrates MJWarp for physics.\n",
        "\n",
        "* [Isaac Lab](https://github.com/isaac-sim/IsaacLab/tree/feature/newton) is a GPU-accelerated, open-source framework designed by NVIDIA for robotics research.  It has beta support for MJWarp through a new physics platform called[Newton](https://developer.nvidia.com/newton-physics).\n",
        "\n",
        "* [mjlab](https://github.com/mujocolab/mjlab) combines Isaac Lab's proven API with best-in-class MuJoCo physics to provide lightweight, modular abstractions for RL robotics research and sim-to-real deployment.\n",
        "\n",
        "ðŸ‘‹ Tawa pona!"
      ],
      "metadata": {
        "id": "gV52wXSWutln"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}